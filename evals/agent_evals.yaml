description: |
  Evaluates a database Q&A agent that generates SQL queries to answer natural language questions about an e-commerce database.

models:
  - provider: "anthropic"
    name: "claude-haiku-4-5"
    temperature: 0.5
  - provider: "openai"
    name: "gpt-4o-mini"
    temperature: 0.5

eval:
  samples: 10
  success_threshold: 0.6

categories:
  customer_queries:
    name: "Customer Queries"
    description: "Tests SQL generation for customer lookups, filtering, and aggregation."
    test_cases:
      - id: "count-customers"
        input:
          question: "How many customers are in the database?"
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["customers"]
          answer: "There are 8 customers."
        metadata:
          description: "Aggregate COUNT query on a single table"

      - id: "customer-lookup"
        input:
          question: "What is the email address of Alice Johnson?"
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["customers"]
          answer: "alice@example.com"
        metadata:
          description: "Lookup a specific field by customer name"

      - id: "customers-by-country"
        input:
          question: "Which customers are from the United States?"
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["customers"]
          answer: "Alice Johnson, Frank Wilson, and Hassan Ali."
        metadata:
          description: "Filter customers with a WHERE clause"

  product_queries:
    name: "Product Queries"
    description: "Tests SQL generation for product ranking and category filtering."
    test_cases:
      - id: "top-expensive-products"
        input:
          question: "What are the top 3 most expensive products?"
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["products"]
          answer: "Laptop Pro ($1299.99), Coffee Maker ($159.99), and Running Shoes ($89.99)."
        metadata:
          description: "ORDER BY with LIMIT to rank products"

      - id: "products-in-category"
        input:
          question: "List all products in the Electronics category."
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["products"]
          answer: "Laptop Pro and Wireless Mouse."
        metadata:
          description: "Filter products by category"

  order_queries:
    name: "Order Queries"
    description: "Tests SQL generation for order filtering, aggregation, and cross-table joins."
    test_cases:
      - id: "pending-orders"
        input:
          question: "List all pending orders."
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["orders"]
          answer: "Orders 4, 8, and 11 are pending."
        metadata:
          description: "Filter orders by status"

      - id: "total-revenue"
        input:
          question: "What is the total revenue from completed orders?"
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["orders"]
          answer: "$3029.89"
        metadata:
          description: "Aggregate SUM with a status filter"

      - id: "orders-in-january"
        input:
          question: "How many orders were placed in January 2025?"
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["orders"]
          answer: "5 orders were placed in January 2025."
        metadata:
          description: "COUNT with date range filtering"

      - id: "customer-orders-join"
        input:
          question: "Which customers have placed orders? List their names."
        expected:
          tool_name: "generate_sql"
          must_reference_tables: ["customers", "orders"]
          answer: "Alice Johnson, Bob Smith, Carlos Garcia, Diana Chen, Eva Mueller, Frank Wilson, Grace Kim, and Hassan Ali."
        metadata:
          description: "JOIN across customers and orders tables"

checks:
  - type: "equals"
    arguments:
      actual: "$.output.value.prediction_count"
      expected: 1
    metadata:
      name: "Single Tool Call"
      description: "Agent made exactly one tool call"

  - type: "exact_match"
    arguments:
      actual: "$.output.value.tool_predictions[0].tool_name"
      expected: "$.test_case.expected.tool_name"
    metadata:
      name: "Correct Tool"
      description: "Agent selected the generate_sql tool"

  - type: "contains"
    arguments:
      text: "$.output.value.sql_query"
      phrases: "$.test_case.expected.must_reference_tables"
      case_sensitive: false
    metadata:
      name: "SQL References Tables"
      description: "Generated SQL references the expected tables"

  - type: "equals"
    arguments:
      actual: "$.output.value.query_success"
      expected: true
    metadata:
      name: "Query Succeeded"
      description: "SQL query executed without errors"

  - type: "llm_judge"
    arguments:
      judge_model: "claude-haiku-4-5"
      prompt: |
        You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.

        Question:

        ```
        {{$.test_case.input.question}}
        ```

        Expected Answer:

        ```
        {{$.test_case.expected.answer}}
        ```

        SQL Query Result:

        ```
        {{$.output.value.query_result}}
        ```

        Agent Response:

        ```
        {{$.output.value.response}}
        ```

        Did the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.
    metadata:
      name: "Response Quality"
      description: "LLM judges whether the response correctly answers the question"
