{
  "evaluation_id": "4cbf2295-85d6-4239-8a06-43de3e5307b1",
  "started_at": "2026-02-23T23:12:49.076012+00:00",
  "completed_at": "2026-02-23T23:12:56.282219+00:00",
  "status": "completed",
  "summary": {
    "total_test_cases": 30,
    "completed_test_cases": 30,
    "error_test_cases": 0
  },
  "results": [
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 3.0670469170072465
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.0918238162994385
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277120+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277273+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277353+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277419+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question \"How many customers are in the database?\" The SQL query result shows 8 total customers, and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"in the database\" vs just stating the number), the factual content is correct and the response directly answers the question asked. The data accuracy is perfect.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 144,
              "total_cost": 0.001604,
              "duration_seconds": 2.1493105000045034
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.313729+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.928760542003147
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.9491071701049805
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277450+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277472+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277517+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277552+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response correctly identifies the email address of Alice Johnson as alice@example.com, which matches the expected answer and the SQL query result. The agent provided the factually correct information in a clear, natural language format. While the wording differs slightly from the expected answer (the agent provided a complete sentence rather than just the email address), the core fact is accurate and the response appropriately answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 140,
              "total_cost": 0.00159,
              "duration_seconds": 2.2514016659988556
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.339592+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 66,
              "input_cost": 5.82e-05,
              "output_cost": 3.96e-05,
              "total_cost": 9.779999999999999e-05,
              "duration_seconds": 3.3735305829977733
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.3943088054656982
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277573+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277595+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277631+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277661+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. The SQL query result confirms these are the only three customers with \"United States\" as their country. While the agent's response includes additional information (email addresses) that wasn't in the expected answer, this is supplementary detail that doesn't contradict or change the core facts. The agent correctly answered the question by identifying the right customers, and the wording difference (listing format with emails vs. simple comma-separated names) is acceptable as the instructions state \"wording does not need to be exact, but the facts and data must be correct.\"",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1015,
              "output_tokens": 189,
              "total_cost": 0.00196,
              "duration_seconds": 2.5374848329956876
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.361624+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS customer_count FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS customer_count FROM customers;",
            "query_result": {
              "columns": [
                "customer_count"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 302,
              "output_tokens": 31,
              "input_cost": 4.53e-05,
              "output_cost": 1.8599999999999998e-05,
              "total_cost": 6.39e-05,
              "duration_seconds": 2.7139616669956013
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.732808828353882
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277682+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277702+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS customer_count FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277828+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277876+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question \"How many customers are in the database?\" The SQL query result shows a customer_count of 8, and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"There are 8 customers in the database\" vs \"There are 8 customers\"), the facts and data are correct, and the additional context \"in the database\" actually provides helpful clarification. The core information matches perfectly.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 162,
              "total_cost": 0.001694,
              "duration_seconds": 2.22133191699686
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"customer_count\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.382237+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.676754250001977
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.6970200538635254
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277908+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277933+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.277971+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278007+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response correctly identifies the email address of Alice Johnson as alice@example.com, which matches the expected answer and the SQL query result data. The agent provided the factually correct information in a clear, natural language format. While the wording differs slightly from the expected answer (the agent provided a complete sentence rather than just the email address), the core fact is accurate and the response appropriately answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 141,
              "total_cost": 0.001595,
              "duration_seconds": 2.249075708001328
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.401462+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 3.1995741659993655
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.2209761142730713
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278029+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278053+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278093+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278129+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. The SQL query results confirm these are the only three customers with \"United States\" as their country. While the agent's response included additional information (email addresses) beyond the expected answer, this is supplementary detail that does not contradict or diminish the correctness of the core answer. The facts are accurate and complete - all three customers mentioned in the expected answer are present in the agent's response.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1006,
              "output_tokens": 158,
              "total_cost": 0.0017959999999999999,
              "duration_seconds": 2.4011923750003916
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.419955+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.6001703739966615
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.6191341876983643
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278152+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278174+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278209+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278243+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question \"How many customers are in the database?\" The SQL query result shows 8 total customers, and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"There are 8 customers\" vs \"There are 8 customers in the database\"), the factual content is identical and correct. The agent provided the accurate data point requested.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 150,
              "total_cost": 0.001634,
              "duration_seconds": 2.153422582996427
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.438407+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 3.030463665993011
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.0563671588897705
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278265+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278313+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278351+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278385+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified and provided the email address of Alice Johnson. The SQL query result shows that alice@example.com is the correct email address, and the agent's response accurately states \"The email address of Alice Johnson is alice@example.com.\" The factual data matches the expected answer exactly, and the response is appropriately formatted and clear.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 126,
              "total_cost": 0.00152,
              "duration_seconds": 1.9254094999996596
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.456913+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 3.0852125419987715
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.1066267490386963
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278409+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278432+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278466+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278497+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. While the agent's response format differs slightly from the expected answer (using a numbered list with email addresses instead of a comma-separated list), the core facts are accurate and complete. The agent included the correct customer names and even provided additional helpful information (email addresses) that was available in the query results. The data matches the SQL query results perfectly, and all three customers are correctly identified as being from the United States.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1006,
              "output_tokens": 161,
              "total_cost": 0.0018110000000000001,
              "duration_seconds": 2.2371486659976654
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.475818+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.5854540829968755
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.6041371822357178
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278518+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278539+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278571+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278603+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question \"How many customers are in the database?\" The SQL query result shows 8 total customers, and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"There are 8 customers.\" vs \"There are 8 customers in the database.\"), the facts and data are correct. The agent's response is more complete by explicitly mentioning \"in the database,\" which actually provides better clarity. The core factual content matches perfectly.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 170,
              "total_cost": 0.0017339999999999999,
              "duration_seconds": 2.3227522919987678
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.494362+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.6900673339987407
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.7090981006622314
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278624+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278644+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278677+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278710+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response correctly identifies the email address of Alice Johnson as alice@example.com, which matches the expected answer and the SQL query result data. The agent provided the factually correct information in a clear, natural language format. While the wording differs slightly from the expected answer (the agent provided a complete sentence rather than just the email address), the core fact is accurate and the response appropriately answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 141,
              "total_cost": 0.001595,
              "duration_seconds": 2.0385966249959893
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.512756+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 66,
              "input_cost": 5.82e-05,
              "output_cost": 3.96e-05,
              "total_cost": 9.779999999999999e-05,
              "duration_seconds": 3.469380499998806
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.489001989364624
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278731+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278752+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278786+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278817+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response correctly identifies all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. While the agent provided additional information (email addresses) beyond what was in the expected answer, this is supplementary detail that does not contradict or change the core facts. The expected answer lists the three correct names, and the agent's response includes all three names with accurate information. The wording differs (the agent uses a numbered list format rather than a comma-separated list), but the facts and data are correct and complete.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1015,
              "output_tokens": 165,
              "total_cost": 0.00184,
              "duration_seconds": 2.3180931669994607
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.531216+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 3.0078812080028
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.0269289016723633
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278838+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278859+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278893+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278924+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question \"How many customers are in the database?\" The SQL query result shows 8 total customers, and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"There are 8 customers.\" vs \"There are 8 customers in the database.\"), the facts and data are correct. The agent's version is actually more complete as it explicitly mentions \"in the database,\" which directly addresses the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 164,
              "total_cost": 0.001704,
              "duration_seconds": 2.2222178329975577
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.549730+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 3.5838348329925793
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.6145999431610107
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278943+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278962+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.278994+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.279025+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response correctly identifies the email address of Alice Johnson as alice@example.com, which matches the expected answer and the SQL query result data. While the agent's response includes additional context (\"The email address of Alice Johnson is\") compared to the expected answer format, the core factual information is accurate and directly addresses the question asked. The wording difference is acceptable as per the evaluation criteria.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 136,
              "total_cost": 0.00157,
              "duration_seconds": 1.9137718339989078
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.568059+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 66,
              "input_cost": 5.82e-05,
              "output_cost": 3.96e-05,
              "total_cost": 9.779999999999999e-05,
              "duration_seconds": 3.084616583000752
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.1038260459899902
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.279046+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.279066+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.279099+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.279127+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. The SQL query results confirm these are the only three customers with \"United States\" as their country. While the agent's response included additional information (email addresses) beyond the expected answer, this is supplementary detail that does not contradict or diminish the correctness of the core answer. The agent provided all the required names in the correct format and with accurate information.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1015,
              "output_tokens": 151,
              "total_cost": 0.00177,
              "duration_seconds": 2.077777792001143
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.586226+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.922929667009157
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.9457647800445557
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.279145+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286704+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286791+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286831+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question \"How many customers are in the database?\" The SQL query result shows 8 total customers, and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"There are 8 customers in the database\" vs \"There are 8 customers\"), the facts and data are correct. The additional phrase \"in the database\" in the agent's response actually provides helpful clarification and does not contradict the expected answer.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 166,
              "total_cost": 0.001714,
              "duration_seconds": 1.9313548330028425
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.604564+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.5447741669995594
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.5648179054260254
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286854+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286872+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286911+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286936+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response correctly identifies the email address of Alice Johnson as alice@example.com, which matches the expected answer and the SQL query result data. While the agent provided a more complete sentence format compared to the expected answer, the factual content is accurate and the email address is correct. The wording difference is acceptable as per the evaluation criteria.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 126,
              "total_cost": 0.00152,
              "duration_seconds": 1.755440583001473
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.623064+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 3.9399688329940545
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.9657652378082275
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286951+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286965+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.286989+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287013+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. The SQL query result confirms these are the only three customers with \"United States\" as their country. While the agent's response included additional information (email addresses) beyond the expected answer, this is supplementary detail that does not contradict or diminish the correctness of the core answer. The facts are accurate and complete - all three customers mentioned in the expected answer are present in the agent's response.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1006,
              "output_tokens": 158,
              "total_cost": 0.0017959999999999999,
              "duration_seconds": 1.9566132920008386
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.641797+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.5069705420028185
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.5273141860961914
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287028+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287043+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287069+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287092+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question. The SQL query result shows 8 customers (total_customers = 8), and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"in the database\" vs just stating the fact), the core information is identical and correct. The agent successfully extracted and communicated the correct data from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 144,
              "total_cost": 0.001604,
              "duration_seconds": 1.9461339170011343
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.660187+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.741319666005438
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.761798143386841
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287106+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287128+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287152+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287175+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified and provided the email address of Alice Johnson as alice@example.com, which matches the expected answer. The SQL query result confirms this is the correct data from the database. While the agent's response includes additional context (\"The email address of Alice Johnson is\") compared to just the expected answer format, the factual content is accurate and directly answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 132,
              "total_cost": 0.0015500000000000002,
              "duration_seconds": 2.4773541670001578
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.678866+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 66,
              "input_cost": 5.82e-05,
              "output_cost": 3.96e-05,
              "total_cost": 9.779999999999999e-05,
              "duration_seconds": 2.94466641699546
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.964524030685425
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287190+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287204+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287228+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287249+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. The SQL query results confirm these are the only three customers with \"United States\" as their country. While the agent's response included additional information (email addresses) beyond the expected answer, this is supplementary detail that does not contradict or misrepresent the facts. The core requirement\u2014identifying which customers are from the United States\u2014was answered accurately and completely. The wording differs from the expected answer (using a numbered list format instead of a comma-separated list), but the instructions specify that exact wording is not required as long as facts and data are correct, which they are.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1015,
              "output_tokens": 197,
              "total_cost": 0.002,
              "duration_seconds": 2.4274083339987556
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.697387+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.38799304200802
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.4078967571258545
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287264+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287278+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287301+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287323+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question \"How many customers are in the database?\" The SQL query result shows 8 total customers, and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"There are 8 customers in the database\" vs \"There are 8 customers\"), the factual content is identical and correct. The agent properly conveyed the accurate data from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 154,
              "total_cost": 0.001654,
              "duration_seconds": 1.8246709589948296
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.715893+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.3395205839988193
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.369265079498291
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287337+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287351+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287375+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287398+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified and provided the email address of Alice Johnson as alice@example.com, which matches the expected answer. The SQL query result confirms this is the correct data from the database. While the agent's response includes additional context (\"The email address of Alice Johnson is\") compared to just the expected answer format, the factual content is accurate and directly answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 132,
              "total_cost": 0.0015500000000000002,
              "duration_seconds": 1.6966519999987213
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.734377+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 3.3251287500024773
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.348449945449829
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287413+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287428+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287452+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287475+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. While the agent's response format differs from the expected answer (providing a numbered list with email addresses rather than a comma-separated list of names only), the core facts are accurate and complete. The agent included all the correct customers and no incorrect ones. The additional information (email addresses) is factually correct and helpful, and does not contradict the expected answer. The wording does not need to be exact as specified in the evaluation criteria.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1006,
              "output_tokens": 166,
              "total_cost": 0.001836,
              "duration_seconds": 2.170133833998989
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.752907+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.536229290999472
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.561458110809326
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287490+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287504+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287529+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287551+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question \"How many customers are in the database?\" The SQL query result shows 8 customers (total_customers: 8), and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"There are 8 customers in the database\" vs \"There are 8 customers\"), the factual content is identical and correct. The agent properly conveyed the accurate data from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 160,
              "total_cost": 0.001684,
              "duration_seconds": 2.4872759169957135
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.771515+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.4531605830052285
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.472559690475464
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287565+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287579+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287602+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287624+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified and provided the email address of Alice Johnson as alice@example.com, which matches the expected answer. The SQL query result confirms this is the correct data from the database. While the agent's response includes additional context (\"The email address of Alice Johnson is\") compared to just the expected answer format, the core factual information is accurate and directly answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 133,
              "total_cost": 0.001555,
              "duration_seconds": 1.68349616699561
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.790478+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 3.0221712080019643
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.042234182357788
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287638+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287652+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287676+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287698+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. The SQL query result confirms these are the only three customers with \"United States\" as their country. While the agent's response included additional information (email addresses) beyond the expected answer, this is supplementary detail that does not contradict or change the core facts. The agent correctly answered which customers are from the United States, matching the expected answer in substance.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1006,
              "output_tokens": 149,
              "total_cost": 0.001751,
              "duration_seconds": 1.7869915829942329
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.809202+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "There are 8 customers."
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS customer_count FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS customer_count FROM customers;",
            "query_result": {
              "columns": [
                "customer_count"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 302,
              "output_tokens": 31,
              "input_cost": 4.53e-05,
              "output_cost": 1.8599999999999998e-05,
              "total_cost": 6.39e-05,
              "duration_seconds": 2.606153542001266
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.631511688232422
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287711+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287726+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS customer_count FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287750+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287773+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response \"There are 8 customers in the database.\" correctly answers the question. The SQL query result shows a customer_count of 8, and the agent accurately reported this number. While the wording differs slightly from the expected answer (\"There are 8 customers.\" vs \"There are 8 customers in the database.\"), the factual content is identical and correct. The agent properly conveyed the accurate data from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 884,
              "output_tokens": 149,
              "total_cost": 0.001629,
              "duration_seconds": 1.6096825419954257
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nHow many customers are in the database?\n```\n\nExpected Answer:\n\n```\nThere are 8 customers.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"customer_count\"], \"rows\": [[8]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThere are 8 customers in the database.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.827794+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "alice@example.com"
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.3223747919982998
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.345242738723755
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287787+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287801+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287824+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287847+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response correctly identifies the email address of Alice Johnson as alice@example.com, which matches the expected answer and the SQL query result data. The agent provided the factually correct information in a clear, natural language format. While the wording differs slightly from the expected answer (the agent provided a complete sentence rather than just the email address), the core fact is accurate and the response appropriately answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 890,
              "output_tokens": 141,
              "total_cost": 0.001595,
              "duration_seconds": 1.702251750000869
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhat is the email address of Alice Johnson?\n```\n\nExpected Answer:\n\n```\nalice@example.com\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\n```\n\nAgent Response:\n\n```\nThe email address of Alice Johnson is alice@example.com.\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.846257+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ],
            "answer": "Alice Johnson, Frank Wilson, and Hassan Ali."
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 3.0851054579979973
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.104731798171997
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287860+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287874+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287897+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.287919+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent's response correctly identifies all three customers from the United States: Alice Johnson, Frank Wilson, and Hassan Ali. While the agent provided additional information (email addresses) beyond what was in the expected answer, this is not incorrect\u2014it's supplementary detail from the query results. The core facts match perfectly: all three customers listed are indeed from the United States, and no customers are missing or incorrectly included. The wording differs slightly from the expected answer (using a numbered list format instead of a comma-separated list), but the instruction states that wording does not need to be exact as long as facts and data are correct, which they are.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 1006,
              "output_tokens": 189,
              "total_cost": 0.001951,
              "duration_seconds": 2.1660740000006626
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the expected answer, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion:\n\n```\nWhich customers are from the United States?\n```\n\nExpected Answer:\n\n```\nAlice Johnson, Frank Wilson, and Hassan Ali.\n```\n\nSQL Query Result:\n\n```\n{\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\n```\n\nAgent Response:\n\n```\nThe customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n```\n\nDid the agent's response match the expected answer? The wording does not need to be exact, but the facts and data must be correct. Currency values do not need to be exact to the cent and can be reasonably rounded.\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x105612520>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T23:12:53.865021+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    }
  ],
  "metadata": {
    "eval_name": "Customer Queries",
    "eval_description": "Tests SQL generation for customer lookups, filtering, and aggregation.",
    "_test_config": {
      "test_function": "test_customer_queries",
      "test_module": "evals.test_agent",
      "samples": 10,
      "success_threshold": 0.6,
      "max_concurrency": null,
      "num_test_cases": 3
    },
    "_test_results": {
      "passed_samples": 10,
      "failed_samples": 0,
      "total_samples": 10,
      "success_rate": 1.0,
      "success_threshold": 0.6,
      "passed": true
    }
  }
}