{
  "evaluation_id": "be1b9be1-850f-49d7-9855-ceaf6db7ce8f",
  "started_at": "2026-02-23T18:31:07.262753+00:00",
  "completed_at": "2026-02-23T18:31:10.639198+00:00",
  "status": "completed",
  "summary": {
    "total_test_cases": 30,
    "completed_test_cases": 30,
    "error_test_cases": 0
  },
  "results": [
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.5820622080009343
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.6078379154205322
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266119+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266269+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266350+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266407+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows a single row with a column \"total_customers\" containing the value 8. The agent's response \"There are 8 customers in the database\" accurately reflects this data and directly answers the question \"How many customers are in the database?\"",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 118,
              "total_cost": 0.0014039999999999999
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.272539+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.4200490420007554
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.4432871341705322
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266438+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266466+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266524+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266561+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 106,
              "total_cost": 0.001352
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.313221+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (alice@example.com)\n2. Frank Wilson (frank@example.com)\n3. Hassan Ali (hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 61,
              "input_cost": 5.82e-05,
              "output_cost": 3.6599999999999995e-05,
              "total_cost": 9.48e-05,
              "duration_seconds": 2.8594240009988425
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.882733106613159
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266579+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266606+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266643+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266680+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson (alice@example.com) - confirmed in row 1 with country \"United States\"\n2. Frank Wilson (frank@example.com) - confirmed in row 2 with country \"United States\"\n3. Hassan Ali (hassan@example.com) - confirmed in row 3 with country \"United States\"\n\nThe agent provided the relevant information (names and emails) in a clear, organized format that directly answers the question. All data matches the query results exactly, and no customers were omitted or incorrectly included.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 936,
              "output_tokens": 197,
              "total_cost": 0.001921
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson (alice@example.com)\n2. Frank Wilson (frank@example.com)\n3. Hassan Ali (hassan@example.com)\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.341267+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS customer_count FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS customer_count FROM customers;",
            "query_result": {
              "columns": [
                "customer_count"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 302,
              "output_tokens": 31,
              "input_cost": 4.53e-05,
              "output_cost": 1.8599999999999998e-05,
              "total_cost": 6.39e-05,
              "duration_seconds": 5.116049291000309
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 5.138906240463257
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266705+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266728+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS customer_count FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266765+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266795+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows a single row with a customer_count value of 8, and the agent's response accurately states \"There are 8 customers in the database.\" The response directly matches the data provided and correctly answers the user's question about the total number of customers.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 119,
              "total_cost": 0.001409
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"customer_count\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.366325+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson'"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson'",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.468301416000031
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.4911386966705322
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266818+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266844+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson'"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266883+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266917+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 106,
              "total_cost": 0.001352
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.389603+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (alice@example.com)\n2. Frank Wilson (frank@example.com)\n3. Hassan Ali (hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 61,
              "input_cost": 5.82e-05,
              "output_cost": 3.6599999999999995e-05,
              "total_cost": 9.48e-05,
              "duration_seconds": 3.1056586670001707
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.128627061843872
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266955+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.266973+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267021+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267056+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson (alice@example.com) - confirmed in row 1 with country \"United States\"\n2. Frank Wilson (frank@example.com) - confirmed in row 2 with country \"United States\"\n3. Hassan Ali (hassan@example.com) - confirmed in row 3 with country \"United States\"\n\nThe agent's response is complete, accurate, and directly answers the question asked. All customers from the United States in the query results are included, and no incorrect customers are listed.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 936,
              "output_tokens": 190,
              "total_cost": 0.001886
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson (alice@example.com)\n2. Frank Wilson (frank@example.com)\n3. Hassan Ali (hassan@example.com)\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.412463+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS customer_count FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS customer_count FROM customers;",
            "query_result": {
              "columns": [
                "customer_count"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 302,
              "output_tokens": 31,
              "input_cost": 4.53e-05,
              "output_cost": 1.8599999999999998e-05,
              "total_cost": 6.39e-05,
              "duration_seconds": 2.3715939169997
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.3946681022644043
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267083+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267100+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS customer_count FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267136+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267170+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows a single row with a customer_count value of 8, and the agent accurately reported \"There are 8 customers in the database.\" The response directly matches the data provided and correctly answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 110,
              "total_cost": 0.001364
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"customer_count\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.435516+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.3588650839992624
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.392235040664673
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267203+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267220+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267253+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267285+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided and answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 108,
              "total_cost": 0.001362
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.461925+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 66,
              "input_cost": 5.82e-05,
              "output_cost": 3.96e-05,
              "total_cost": 9.779999999999999e-05,
              "duration_seconds": 2.871255624000696
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.8943538665771484
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267310+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267344+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267381+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267419+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson with email alice@example.com\n2. Frank Wilson with email frank@example.com\n3. Hassan Ali with email hassan@example.com\n\nAll three customers have \"United States\" in their country field in the database results, and the agent's response matches the query data perfectly. The response is complete, accurate, and directly answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 942,
              "output_tokens": 157,
              "total_cost": 0.001727
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.489588+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS customer_count FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS customer_count FROM customers;",
            "query_result": {
              "columns": [
                "customer_count"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 302,
              "output_tokens": 31,
              "input_cost": 4.53e-05,
              "output_cost": 1.8599999999999998e-05,
              "total_cost": 6.39e-05,
              "duration_seconds": 2.193404500001634
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.219632148742676
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267438+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267460+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS customer_count FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267496+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267529+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows a single row with a customer_count value of 8, and the agent accurately reported \"There are 8 customers in the database.\" The response directly matches the data provided and correctly answers the user's question about the total number of customers.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 117,
              "total_cost": 0.001399
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"customer_count\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.513839+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.251673041999311
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.274420976638794
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267551+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267573+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267608+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267641+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 106,
              "total_cost": 0.001352
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.538377+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 2.882828249999875
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.905780076980591
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267662+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267688+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267727+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267762+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson (id: 1, email: alice@example.com, country: United States)\n2. Frank Wilson (id: 6, email: frank@example.com, country: United States)\n3. Hassan Ali (id: 8, email: hassan@example.com, country: United States)\n\nThe agent provided the relevant information (names and emails) in a clear, organized format that directly answers the question. All data matches the SQL query results exactly, and no customers were omitted or incorrectly included.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 933,
              "output_tokens": 195,
              "total_cost": 0.001908
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.562771+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS customer_count FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS customer_count FROM customers;",
            "query_result": {
              "columns": [
                "customer_count"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 302,
              "output_tokens": 31,
              "input_cost": 4.53e-05,
              "output_cost": 1.8599999999999998e-05,
              "total_cost": 6.39e-05,
              "duration_seconds": 2.9237281670011726
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.946776866912842
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267784+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267804+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS customer_count FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267844+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267889+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows a single row with a customer_count value of 8, and the agent accurately reported \"There are 8 customers in the database.\" The response directly matches the data provided and correctly answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 110,
              "total_cost": 0.001364
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"customer_count\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.586766+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.40235095800017
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.425189971923828
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267911+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267932+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.267971+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268000+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided by the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 107,
              "total_cost": 0.001357
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.611090+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 66,
              "input_cost": 5.82e-05,
              "output_cost": 3.96e-05,
              "total_cost": 9.779999999999999e-05,
              "duration_seconds": 3.2209572910014685
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.243946075439453
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268023+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268044+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268083+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268118+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson with email alice@example.com\n2. Frank Wilson with email frank@example.com\n3. Hassan Ali with email hassan@example.com\n\nAll three customers have \"United States\" in their country field in the query results, and the agent's response matches the data exactly. The response is complete, accurate, and directly answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 942,
              "output_tokens": 156,
              "total_cost": 0.001722
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson (Email: alice@example.com)\n2. Frank Wilson (Email: frank@example.com)\n3. Hassan Ali (Email: hassan@example.com)\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.635902+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.287226250000458
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.309864044189453
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268136+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268158+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268198+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.268239+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows that there is 1 row with a \"total_customers\" column value of 8. The agent's response \"There are 8 customers in the database\" accurately reflects this data. The answer is direct, clear, and matches the query result exactly.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 121,
              "total_cost": 0.0014190000000000001
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.660300+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson'"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson'",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.1277202910023334
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.150125741958618
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270093+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270120+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson'"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270181+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270213+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 106,
              "total_cost": 0.001352
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.684465+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 2.625940415999139
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.6486001014709473
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270232+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270256+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270288+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270317+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson (id: 1, email: alice@example.com, country: United States)\n2. Frank Wilson (id: 6, email: frank@example.com, country: United States)\n3. Hassan Ali (id: 8, email: hassan@example.com, country: United States)\n\nThe agent provided the names and email addresses for each customer, which directly answers the question \"Which customers are from the United States?\" The information matches the query results exactly, with all three rows from the result set properly represented in the response.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 933,
              "output_tokens": 199,
              "total_cost": 0.001928
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.709381+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS customer_count FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS customer_count FROM customers;",
            "query_result": {
              "columns": [
                "customer_count"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 302,
              "output_tokens": 31,
              "input_cost": 4.53e-05,
              "output_cost": 1.8599999999999998e-05,
              "total_cost": 6.39e-05,
              "duration_seconds": 2.129820000000109
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.1573948860168457
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270350+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270369+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS customer_count FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270400+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270430+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows a single row with a customer_count value of 8, and the agent accurately reported \"There are 8 customers in the database.\" The response directly matches the data provided and correctly answers the user's question about the total number of customers.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 117,
              "total_cost": 0.001399
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"customer_count\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.734026+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.2076286249994155
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.230437994003296
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270452+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270476+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270512+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270545+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 106,
              "total_cost": 0.001352
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.758579+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 2.6541470830015896
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.6773838996887207
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270566+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270585+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270618+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270650+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson (id: 1, email: alice@example.com, country: United States)\n2. Frank Wilson (id: 6, email: frank@example.com, country: United States)\n3. Hassan Ali (id: 8, email: hassan@example.com, country: United States)\n\nThe agent provided the names and email addresses for each customer, which directly answers the question \"Which customers are from the United States?\" The information matches the query results exactly, with all three rows from the result set properly represented in the response.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 933,
              "output_tokens": 199,
              "total_cost": 0.001928
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.783252+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.1403489999993326
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.163663148880005
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270668+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270689+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270725+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270757+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The SQL query result shows that there is 1 row with a column \"total_customers\" containing the value 8. The agent's response states \"There are 8 customers in the database,\" which directly and accurately reflects the data returned by the query. The agent correctly interpreted and communicated the result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 119,
              "total_cost": 0.001409
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.806622+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.169889165999848
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.1930320262908936
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270776+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270797+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270831+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270860+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided from the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 107,
              "total_cost": 0.001357
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.830165+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 3.593340207999063
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 3.616858720779419
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270879+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270898+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270927+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270956+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson (id: 1, country: United States)\n2. Frank Wilson (id: 6, country: United States)\n3. Hassan Ali (id: 8, country: United States)\n\nThe agent provided the names and email addresses for each customer, which directly answers the question \"Which customers are from the United States?\" The information matches the query results exactly, with all three rows from the result set properly represented in the response.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 933,
              "output_tokens": 175,
              "total_cost": 0.001808
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.853620+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS customer_count FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS customer_count FROM customers;",
            "query_result": {
              "columns": [
                "customer_count"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 302,
              "output_tokens": 31,
              "input_cost": 4.53e-05,
              "output_cost": 1.8599999999999998e-05,
              "total_cost": 6.39e-05,
              "duration_seconds": 2.0965297909988294
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.1193950176239014
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270974+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.270992+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS customer_count FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271023+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271051+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows a single row with a customer_count value of 8, and the agent accurately reported \"There are 8 customers in the database.\" The response directly matches the data provided and correctly answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 110,
              "total_cost": 0.001364
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"customer_count\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.877134+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.2567510410008254
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.2795562744140625
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271069+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271086+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271116+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271144+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result returned one row with the email column containing \"alice@example.com\", and the agent's response accurately states that the email address of Alice Johnson is alice@example.com. The response directly matches the data provided by the query result.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 114,
              "total_cost": 0.001392
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.900157+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson (alice@example.com)\n2. Frank Wilson (frank@example.com)\n3. Hassan Ali (hassan@example.com)",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 61,
              "input_cost": 5.82e-05,
              "output_cost": 3.6599999999999995e-05,
              "total_cost": 9.48e-05,
              "duration_seconds": 2.9340603330001613
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.957467794418335
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271161+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271178+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271207+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271235+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson (alice@example.com) - country: United States\n2. Frank Wilson (frank@example.com) - country: United States\n3. Hassan Ali (hassan@example.com) - country: United States\n\nAll three customers in the query result have \"United States\" as their country value, and the agent's response includes all of them with their correct names and email addresses. The answer is complete, accurate, and directly addresses the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 936,
              "output_tokens": 178,
              "total_cost": 0.001826
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson (alice@example.com)\n2. Frank Wilson (frank@example.com)\n3. Hassan Ali (hassan@example.com)\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.923101+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "How many customers are in the database?"
          },
          "id": "count-customers",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Aggregate COUNT query on a single table"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT COUNT(*) AS total_customers FROM customers;"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT COUNT(*) AS total_customers FROM customers;",
            "query_result": {
              "columns": [
                "total_customers"
              ],
              "rows": [
                [
                  8
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "There are 8 customers in the database.",
            "usage": {
              "input_tokens": 304,
              "output_tokens": 32,
              "input_cost": 4.56e-05,
              "output_cost": 1.92e-05,
              "total_cost": 6.48e-05,
              "duration_seconds": 2.0428204579984595
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.0672411918640137
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271252+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271270+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT COUNT(*) AS total_customers FROM customers;"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271300+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271328+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query result shows a single row with a column \"total_customers\" containing the value 8. The agent's response \"There are 8 customers in the database\" accurately reflects this data and directly answers the question \"How many customers are in the database?\"",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 814,
              "output_tokens": 118,
              "total_cost": 0.0014039999999999999
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: How many customers are in the database?\nSQL Query Result: {\"columns\": [\"total_customers\"], \"rows\": [[8]], \"row_count\": 1}\nAgent Response: There are 8 customers in the database.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.946137+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "What is the email address of Alice Johnson?"
          },
          "id": "customer-lookup",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Lookup a specific field by customer name"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT email FROM customers WHERE name = 'Alice Johnson';",
            "query_result": {
              "columns": [
                "email"
              ],
              "rows": [
                [
                  "alice@example.com"
                ]
              ],
              "row_count": 1
            },
            "query_success": true,
            "response": "The email address of Alice Johnson is alice@example.com.",
            "usage": {
              "input_tokens": 307,
              "output_tokens": 35,
              "input_cost": 4.6049999999999994e-05,
              "output_cost": 2.1e-05,
              "total_cost": 6.705e-05,
              "duration_seconds": 2.7226067919982597
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.7604289054870605
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271345+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271362+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT email FROM customers WHERE name = 'Alice Johnson';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271392+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271420+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly answered the question. The SQL query returned one row with the email column containing \"alice@example.com\", and the agent accurately reported this email address as belonging to Alice Johnson. The response directly matches the data provided and answers the question asked.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 822,
              "output_tokens": 107,
              "total_cost": 0.001357
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: What is the email address of Alice Johnson?\nSQL Query Result: {\"columns\": [\"email\"], \"rows\": [[\"alice@example.com\"]], \"row_count\": 1}\nAgent Response: The email address of Alice Johnson is alice@example.com.\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.968899+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    },
    {
      "status": "completed",
      "execution_context": {
        "test_case": {
          "input": {
            "question": "Which customers are from the United States?"
          },
          "id": "customers-by-country",
          "expected": {
            "tool_name": "generate_sql",
            "must_reference_tables": [
              "customers"
            ]
          },
          "metadata": {
            "description": "Filter customers with a WHERE clause"
          },
          "checks": null
        },
        "output": {
          "value": {
            "tool_predictions": [
              {
                "tool_name": "generate_sql",
                "arguments": {
                  "sql": "SELECT * FROM customers WHERE country = 'United States';"
                }
              }
            ],
            "prediction_count": 1,
            "sql_query": "SELECT * FROM customers WHERE country = 'United States';",
            "query_result": {
              "columns": [
                "id",
                "name",
                "email",
                "country",
                "created_at"
              ],
              "rows": [
                [
                  1,
                  "Alice Johnson",
                  "alice@example.com",
                  "United States",
                  "2024-01-15"
                ],
                [
                  6,
                  "Frank Wilson",
                  "frank@example.com",
                  "United States",
                  "2024-06-18"
                ],
                [
                  8,
                  "Hassan Ali",
                  "hassan@example.com",
                  "United States",
                  "2024-08-30"
                ]
              ],
              "row_count": 3
            },
            "query_success": true,
            "response": "The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com",
            "usage": {
              "input_tokens": 388,
              "output_tokens": 59,
              "input_cost": 5.82e-05,
              "output_cost": 3.54e-05,
              "total_cost": 9.36e-05,
              "duration_seconds": 2.7205427500011865
            },
            "model_name": "gpt-4o-mini",
            "model_provider": "openai",
            "temperature": 0.5
          },
          "id": null,
          "metadata": {
            "duration_seconds": 2.7434182167053223
          }
        }
      },
      "check_results": [
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Single Tool Call",
                "description": "Agent made exactly one tool call"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.prediction_count",
              "value": 1
            },
            "expected": {
              "value": 1,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271437+00:00",
          "metadata": {
            "name": "Single Tool Call",
            "description": "Agent made exactly one tool call"
          },
          "error": null
        },
        {
          "check_type": "exact_match",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Correct Tool",
                "description": "Agent selected the generate_sql tool"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.tool_predictions[0].tool_name",
              "value": "generate_sql"
            },
            "expected": {
              "jsonpath": "$.test_case.expected.tool_name",
              "value": "generate_sql"
            },
            "case_sensitive": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271455+00:00",
          "metadata": {
            "name": "Correct Tool",
            "description": "Agent selected the generate_sql tool"
          },
          "error": null
        },
        {
          "check_type": "contains",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "found": [
              "customers"
            ]
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "SQL References Tables",
                "description": "Generated SQL references the expected tables"
              },
              "resolved_from": "literal"
            },
            "text": {
              "jsonpath": "$.output.value.sql_query",
              "value": "SELECT * FROM customers WHERE country = 'United States';"
            },
            "phrases": {
              "jsonpath": "$.test_case.expected.must_reference_tables",
              "value": [
                "customers"
              ]
            },
            "case_sensitive": {
              "value": false,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            },
            "match_all": {
              "value": true,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271487+00:00",
          "metadata": {
            "name": "SQL References Tables",
            "description": "Generated SQL references the expected tables"
          },
          "error": null
        },
        {
          "check_type": "equals",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true
          },
          "resolved_arguments": {
            "metadata": {
              "value": {
                "name": "Query Succeeded",
                "description": "SQL query executed without errors"
              },
              "resolved_from": "literal"
            },
            "actual": {
              "jsonpath": "$.output.value.query_success",
              "value": true
            },
            "expected": {
              "value": true,
              "resolved_from": "literal"
            },
            "negate": {
              "value": false,
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.271516+00:00",
          "metadata": {
            "name": "Query Succeeded",
            "description": "SQL query executed without errors"
          },
          "error": null
        },
        {
          "check_type": "llm_judge",
          "check_version": "1.0.0",
          "status": "completed",
          "results": {
            "passed": true,
            "reasoning": "The agent correctly identified all three customers from the United States based on the SQL query results. The response accurately lists:\n1. Alice Johnson (id: 1, email: alice@example.com, country: United States)\n2. Frank Wilson (id: 6, email: frank@example.com, country: United States)\n3. Hassan Ali (id: 8, email: hassan@example.com, country: United States)\n\nThe agent provided the names and email addresses for each customer, which directly answers the question \"Which customers are from the United States?\" The information matches the query results exactly, with all three rows from the result set properly represented in the response.",
            "judge_metadata": {
              "judge_model": "claude-haiku-4-5",
              "input_tokens": 933,
              "output_tokens": 199,
              "total_cost": 0.001928
            }
          },
          "resolved_arguments": {
            "prompt": {
              "value": "You are evaluating a database Q&A agent. Given the question, the SQL query result data, and the agent's response, determine whether the agent correctly answered the question.\n\nQuestion: Which customers are from the United States?\nSQL Query Result: {\"columns\": [\"id\", \"name\", \"email\", \"country\", \"created_at\"], \"rows\": [[1, \"Alice Johnson\", \"alice@example.com\", \"United States\", \"2024-01-15\"], [6, \"Frank Wilson\", \"frank@example.com\", \"United States\", \"2024-06-18\"], [8, \"Hassan Ali\", \"hassan@example.com\", \"United States\", \"2024-08-30\"]], \"row_count\": 3}\nAgent Response: The customers from the United States are:\n\n1. Alice Johnson - alice@example.com\n2. Frank Wilson - frank@example.com\n3. Hassan Ali - hassan@example.com\n\nDid the agent correctly answer the question based on the data?\n",
              "resolved_from": "template_processed"
            },
            "response_format": {
              "value": "<class 'evals.test_agent.ResponseJudgement'>",
              "resolved_from": "literal"
            },
            "llm_function": {
              "value": "<function _make_judge_function.<locals>._judge at 0x10b2f74c0>",
              "resolved_from": "literal"
            }
          },
          "evaluated_at": "2026-02-23T18:31:07.991883+00:00",
          "metadata": {
            "name": "Response Quality",
            "description": "LLM judges whether the response correctly answers the question"
          },
          "error": null
        }
      ],
      "summary": {
        "total_checks": 5,
        "completed_checks": 5,
        "error_checks": 0
      },
      "metadata": null
    }
  ],
  "metadata": {
    "eval_name": "Customer Queries",
    "eval_description": "Tests SQL generation for customer lookups, filtering, and aggregation.",
    "_test_config": {
      "test_function": "test_customer_queries",
      "test_module": "evals.test_agent",
      "samples": 10,
      "success_threshold": 0.6,
      "num_test_cases": 3
    },
    "_test_results": {
      "passed_samples": 10,
      "failed_samples": 0,
      "total_samples": 10,
      "success_rate": 1.0,
      "success_threshold": 0.6,
      "passed": true
    }
  }
}